<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang xml:lang>
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Proj_1</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
</head>
<body>
<section id="project-1" class="cell markdown">
<h2>Project 1</h2>
<p>Project 1 is an extention of the Week 2 Lab.</p>
<p>For this assignment, you will be uncompressing audio clips that I have compressed using compression algorithms of my own invention. The compression algorithms works by breaking the audio clip into <em>windows</em>, and then representing each window as a sum of cosines. You will be given data that correspond to a list of frequencies and their associated complex <span class="math inline"><em>A</em></span> values. Using these data, you will uncompress the audio by rebuilding the signal out of cosines.</p>
<p>I used two different methods to try compressing the audio. The steps I did are as follows. Note that in all cases, the sampling frequency is <span class="math inline"><em>F</em><sub><em>s</em></sub> = 44.1</span>kHz.</p>
<p><strong>Method 1</strong></p>
<ul>
<li>First I divided the signal into 50ms windows (which corresponds to 0.050 seconds/window <span class="math inline">×</span> 44100 samples/second = 2205 samples/window)</li>
<li>Then for each window, I determined the top 30 energy-containing frequencies. For each window, I stored those 30 frequencies (in Hertz) along with their corresponding 30 complex A values.</li>
</ul>
<p><strong>Method 2</strong></p>
<ul>
<li>First I divided the signal into 50ms windows (which corresponds to 0.050 seconds/window <span class="math inline">×</span> 44100 samples/second = 2205 samples/window)</li>
<li>Then for each window, I found the energy at 30 different frequencies, evenly spaced between 100 and 2000Hz. The same 30 frequencies were evaluated in each window. For each window, I stored the corresponding 30 complex A values. I didn&#39;t bother saving the frequencies because they just take up space and it is trivial to recompute them in the decompression program.</li>
</ul>
<p>I have also tried an <strong>overlap</strong> modification that works as follows. The compression methods work the same except that each 50ms window overlaps the previous one by 45ms. So if Window 1 covers <span class="math inline">0 &lt; <em>t</em> &lt; 50</span>ms, then Window 2 covers <span class="math inline">5 &lt; <em>t</em> &lt; 55</span>ms and so on. That way each moment in time is partially represented by multiple A values.</p>
<p>Your task is undo this process in order to <em>decompress</em> the audio. The files to decompress are:</p>
<ul>
<li><a href="./files/audio_1_method_1_no_overlap.npz">audio_1_method_1_no_overlap.npz</a></li>
<li><a href="./files/audio_1_method_2_no_overlap.npz">audio_1_method_2_no_overlap.npz</a></li>
<li><a href="./files/audio_2_method_1_no_overlap.npz">audio_2_method_1_no_overlap.npz</a></li>
<li><a href="./files/audio_2_method_2_no_overlap.npz">audio_2_method_2_no_overlap.npz</a></li>
<li><a href="./files/audio_1_method_1_w_overlap.npz">audio_1_method_1_w_overlap.npz</a></li>
<li><a href="./files/audio_1_method_2_w_overlap.npz">audio_1_method_2_w_overlap.npz</a></li>
<li><a href="./files/audio_2_method_1_w_overlap.npz">audio_2_method_1_w_overlap.npz</a></li>
<li><a href="./files/audio_2_method_2_w_overlap.npz">audio_2_method_2_w_overlap.npz</a></li>
</ul>
<p>Confirm your reconstruction works by playing back the audio signals. To do so, first normalize the signal so it is on the range (-1,1):</p>
<p><code>signal = signal / np.max(np.abs(signal))</code></p>
<p>and then play back. I used the <code>sounddevice</code> library (which I had to install into my environment - go to the Anaconda Launcher and work out how to install a new library). I did playback with:</p>
<p><code>import sounddevice as sd</code><br />
<code>sd.play(signal)</code></p>
<p><strong>Questions:</strong> Which compression method sounds better? Why? Which audio signal sounds better when reconstructed? Why? (think about how the qualties of the audio signals fit with the way the compression algorithms work.) What is the compression ratio for each Method?</p>
<p><strong>What to Turn In:</strong> This will be a check-off style project. You&#39;ll show me your code and I&#39;ll ask your a series of questions to see how well you understand your own work.</p>
</section>
</body>
</html>
